# kafka

태그: Kafka

## 토픽

---

### **토픽: 카프카의 토픽 생성 시 파티션 개수 고려사항**

파티션은 카프카의 병렬처리의 핵심이다. 파티션의 개수가 증가할수록 1:1로 매핑되는 컨슈머의 개수를 증가시켜 병렬처리량을 늘릴 수 있기 때문이다.

그러나, 파티션 개수를 늘리게 되면 컨슈머, 브로커에도 부담이 있다. 그렇기에 데이터를 처리함에 있어 지연 발생에 따른 서비스 영향도를 같이 고려하여 파티션 개수를 구하는 것이 중요하다.

**데이터 처리 속도를 올리는 방법**

- 컨슈머 처리량을 늘리는 것

  컨슈머가 실행되는 서버의 사양을 올리는 스케일업, GC 튜닝 등을 활용할수 있다.

  *※ 컨슈머 특성 상 다른 시스템과 연동되기 때문에 일정 수준 이상 처리량을 올리는 것은 매우 어렵다.*

- 컨슈머를 추가해서 병렬 처리량을 늘리는 것

  프로듀서 전송 데이터량 < 컨슈머 데이터 처리량 * 파티션 개수

  만약 전체 컨슈머 데이터 처리량이 프로듀서가 보내는 데이터보다 적다면 컨슈머 랙이 발생하고 데이터 처리 지연이 생기게 된다.

  → 컨슈머 전체 처리량이 프로듀서 데이터 처리량보다 많아야 함


**메시지 키 사용 여부**

메시지 키를 사용함과 동시에 데이터 처리 순서를 지켜야 하는 경우인지를 고려해야 한다. 메시지 키를 사용하게 된다면 파티셔너가 메시지 키를 바탕으로

적절한 파티션을 할당하고 데이터가 전송되게 되는데, 이 경우에 메시키 키에 따라 순서가 보장될 수 있다.

파티션 개수가 변하는 경우

- 기존의 메시지 키 매칭을 그대로 가져가려 한다면?
    - 커스텀 파티셔너를 개발하고 적용해야 한다.

      파티션 개수가 달라지는 순간에는 메시지 키를 사용하는 컨슈머는 특정 메시지 키의 순서를 더 이상 보장받지 못하는 경우가 생기기 때문이다.

      → 변환 이전과 이후 메시지 키의 파티션 위치가 달라짐



**브로커와 컨슈머의 영향도**

카프카에서 파티션은 각 브로커의 파일 시스템을 사용하기에 파티션이 늘어나는 만큼 브로커에서 접근하는 파일 개수가 많아지게 된다.

그러나 운영체제에서는 프로세스당 열 수 있는 파일 최대 개수를 제한하고 있으므로 안정적인 파일 개수를 유지하기 위해서는 각 브로커 당 파일 개수를

모니터링 해야 한다.

### 토픽: 토픽 정리 정책

토픽의 데이터는 시간 또는 용량에 따라 삭제 규칙을 적용할 수 있다.

**토픽 삭제 정책(delete policy)**

토픽의 데이터를 삭제할 때는 세그먼트 단위로 삭제를 진행한다.

*※ 세그먼트: 토픽의 데이터를 저장하는 명시적인 파일 시스템의 단위*

- 파티션마다 별개로 생성되며 세그먼트의 파일 이름은 오프셋 중 가장 작은 값이 된다.
- segment.bytes 크기보다 커질 경우에 기존에 적재하던 세그먼트 파일을 닫고 새로운 세그먼트를 열어서 데이터를 저장한다. (저장 중인 세그먼트 - 액티브 세그먼트)

삭제 정책이 실행되는 시점: 시간 또는 용량이 기준

- retention.ms: 세그먼트 파일의 마지막 수정 시간이 설정 값을 넘어가게 되면 세그먼트는 삭제
- retention.bytes: 토픽의 최대 데이터 크기를 제어. 세그먼트 파일의 크기가 설정 값을 넘어가게 되면 파일 삭제. 삭제된 데이터는 복구할 수 없다.

**토픽 압축 정책(compact policy)**

토픽의 압축이란 메시지 키별로 해당 메시지 키의 레코드 중 오래된 데이터를 삭제하는 정책을 의미한다.

→ 메시지 키를 기준으로 오래된 데이터를 삭제하므로 1개의 파티션에서 오프셋 증가가 일정하지 않을 수 있다.

카프카 스트림즈의 KTable과 같이 메시지 키를 기반으로 데이터를 처리할 경우 유용

압축 정책이 실행되는 시점: 액티브 세그먼트를 제외한 나머지 세그먼트에 한해서만 데이터를 처리

- min.cleanable.dirty.ratio: 액티브 세그먼트를 제외한 세그먼트에 남아 있는 tail 영역 레코드의 개수와 head 영역 레코드 개수의 비율 (dirty / (dirty + clean))

  해당 값을 작게 설정하면 압축이 자주 일어나므로 메시지 키의 최신 데이터만 유지할 수 있지만 브로커에 부담을 줄 수 있다.

  만약 크게 설정한다면 한번 압축을 할 때 많은 데이터가 줄어들게 되므로 압축 효과가 좋지만, 용량 효율은 좋지 않을 수 있다.

  *※ tail 영역 - 브로커 압축 정책에 의해 압축이 완료된 레코드(clean log라고도 함): 압축이 완료되었기 때문에 중복된 메시지가 없다.*

  ※ head 영역 - 압축이 적용되지 않은 레코드(dirty log라고도 함): 중복된 메시지가 존재


## ISR(In-Sync-Replicas)

---

리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태를 의미.

리더 파티션에 데이터가 적재된 이후 팔로워 파티션이 복제하는 시간차 때문에 파티션 간에 오프셋 차이가 발생.

리더 파티션의 모니터링

- [replica.lag.time.max.ms](http://replica.lag.time.max.ms): 해당 주기를 가지고 팔로워 파팉션이 데이터를 복제하는지 확인

  만약 팔로워 파티션이 설정 값보다 더 긴 시간동안 데이터를 가져가지 않는다면 ISR그룹에서 제외한다.


ISR 그룹으로 묶인 파티션의 경우 리더 파티션으로 새로 선출될 자격을 가지게 된다.

- unclean.leader.election.enable: ISR이 아닌 팔로워 파티션을 리더 파티션으로 선출 가능한지 여부를 선택할 수 있는 설정(토픽마다 설정 가능)
    - 리더 파티션으로부터 동기화되지 않은 일부 데이터는 유실될 수 있지만, 토픽을 사용하는 서비스의 중단은 발생하지 않는다.

  만약 리더 파티션으로 선출할 파티션이 없다면 리더 파티션이 존재하는 브로커가 다시 시작되기까지 기다리게 된다.(=서비스 중단)

    ```bash
    kafka-topic --bootstrap-server kafka:9092 \
    --create --topic my-topic \
    --config unclean.leader.election.enable=false
    ```


## 카프카 프로듀서

---

### **acks옵션**

**acks=0**

프로듀서가 리더 파티션으로 데이터를 전송했을 때 리더 파티션에 데이터가 저장되었는지 확인하지 않는다.(보통 리더 파티션은 데이터가 저장된 후 오프셋 값을 리턴)

→ 재시도 설정인 reties 옵션이 무의미, 데이터가 일부 유실되더라도 전송 속도가 중요한 경우에 사용

**acks=1**

리더 파티션에만 정상적으로 적재되었는지 확인한다.(리더 파티션에 데이터가 적재되었음은 보장하지만 데이터가 유실될 수 있다.

→ 리더 파티션에 적재가 완료되어도 팔로워 파티션과 데이터를 동기화하기 직전에 리더 파티션이 있는 브로커에 장애가 발생하는 경우 일부 데이터가 유실될 수 있다.

**acks=all 또는 -1**

리더 파티션과 팔로워 파티션에 모두 정상적으로 적재되었는지 확인한다.

→ 일부 브로커에 장애가 발생하더라도 프로듀서는 안전하게 데이터를 전송하고 저장할 수 있음을 보장할 수 있다.

- min.insync.replicas: acks=all일 때, 프로듀서가 리더 파티션과 팔로워 파티션에 데이터가 적재되었는지 확인하기 위한 최소 ISR 그룹의 파티션 개수(브로커 개수 미만으로!)
    - 해당 값이 1인 경우, 리더 파티션에 적재되었는지 확인. 따라서 ISR 그룹을 대상으로 옵션을 설정한다면 2개 이상으로 설정
    - 운영하는 카프카 브로커 개수가 옵션값보다 작은 경우 프로듀서가 더는 데이터를 전송할 수 없다.

### 멱등성 프로듀서

동일한 데이터를 여러번 전송하더라도 카프카 클러스터에는 한 번만 저장하는 프로듀서의 동작 방식이다.

기본 프로듀서와 달리 프로듀서 PID, 시퀸스 넘버를 함께 전달

→ 동일한 세션에서만 정확히 한번 전달을 보장 (동일한 세션이란 PID의 생명주기를 뜻한다.)

- 시퀸스 넘버는 0부터 시작하여 숫자를 1씩 더한 값이 전달

  순서가 중요한 데이터를 전송하는 프로듀서는 예외가 발생했을 경우 대응하는 방안을 고려해야 한다.


*※ 멱등성 - 여러 번 연산을 수행하더라도 동일한 결과를 나타내는 것*

만약 멱등성 프로듀서로 동작하는 애플리케이션에 이슈가 발생하여 애플리케이션이 재시작되면 PID가 달라지게 되므로 동일한 데이터를 다시 전송할 수 있다.

- enable.idempotence=true
    - 동작 방식 로직이 성립되기 위해 프로듀서의 일부 옵션들이 강제로 설정된다. *(ex.retries=Integer.MAX_VALUE, acks=all)*

### 트랜잭션 프로듀서

다수의 파티션에 데이터를 저장할 경우 모든 데이터에 대해 동일한 원자성을 만족시키기 위해 사용된다.

→ 다수의 데이터를 동일 트랜잭션으로 묶음으로써 전체 데이터를 처리하거나 전체 데이터를 처리하지 않도록 하는 것을 말한다.

- enable.idempotence=true, transactional.id=임의의 String 값으로 정의, isolation.level=read_committed



트랜잭션 프로듀서는 레코드를 파티션에 저장할 뿐만 아니라 트랜잭션의 시작과 끝을 표현하기 위해 트랜잭션 레코드를 전송한다.

*※ 트랜잭션 레코드: 실질적인 데이터는 가지고 있지 않으며 트랜잭션이 끝난 상태를 표시하는 정보만 가지고 있다. 파티션에 저장되어 오프셋을 한 개 차지*

## 카프카 컨슈머

---

### 멀티 스레드 컨슈머

카프카의 처리량을 늘리기 위해 파티션과 컨슈머의 개수를 늘려 운영할 수 있다. 파티션을 여러 개로 운영하는 경우 데이터를 병렬처리하기 위해 개수를 동일하게 맞추는 방법이 있다.

**토픽의 파티션이 N개 일 때**

N개의 스레드를 가진 1개의 프로세스를 운영

- 멀티 스레드로 컨슈머를 안전하게 운영하기 위해서는 고려할 부분이 많다.

  하나의 컨슈머 스레드에서 에외적 상황이 발생해 프로세스 자체가 종료되거나 다른 컨슈머 스레드에게도 영향이 갈 수 있다.

  스레드들이 비정상 종료될 경우 데이터 처리에서 중복이나 유실이 발생할 수 있다.

  컨슈머 스레드 간 영향을 미치지 않도록 스레드 세이프 로직과 변수를 적용


1개의 스레드를 가진 프로세스를 N개 운영

**컨슈머를 멀티 스레드로 활용하는 방법**

- 멀티 워커 스레드 전략 - 컨슈머 스레드 1개만 실행하고 데이터 처리를 담당하는 워커 스레드를 여러 개 실행

  멀티 스레드를 생성하는 ExecutorService 자바 라이브러리를 사용하면 레코드를 병렬처리하는 스레드를 효율적으로 생성하고 관리할 수 있다.

  데이터 처리 환경에 맞는 스레드 풀을 생성해 사용할 수 있다. (ex. CachedThreadPool: 작업 이후 스레드가 종료)

  단점:

    - 오토 커밋을 사용할 때 리밸런싱, 컨슈머 장애 시에 데이터 유실이 발생할 수 있다.
    - 레코드 역전현상이 발생할 수 있다.
        - for반복구문으로 워커 스레드를 생성하는 경우 스레드의 생성 순서는 보장할 수 있지만 레코드 처리의 작업 속도는 보장할 수 없어 순서가 역전될 수 있다.

  ex) 서버 리소스 모니터링 파이프라인, IoT 서비스 센서 데이터 수집 파이프라인


- 컨슈머 멀티 스레드 전략 - 컨슈머 인스턴스에서 poll() 메서드를 호출하는 스레드를 여러 개 띄워서 사용

### 컨슈머 랙

컨슈머 랙은 토픽의 최신 오프셋과 컨슈머 오프셋 간의 차이다.

컨슈머 랙은 컨슈머 그룹 / 토픽 / 파티션별로 생성된다.

*(ex. 하나의 컨슈머 그룹에 1개의 토픽 3개의 파티션이라면 offset을 공유하는 곳이 한 토픽의 3개의 파티션이므로 컨슈머 랙은 총 3개가 될 수 있다.)*

- 컨슈머 랙 증가: 프로듀서가 보내는 데이터 양이 컨슈머의 데이터 처리량보다 큰 경우
- 컨슈머 랙 감소: 프로듀서가 보내는 데이터양이 컨슈머의 데이터 처리량보다 적은 경우(=지연이 없다고 볼 수 있다)

따라서 컨슈머 랙을 모니터링 하는 것은 카프카를 통한 데이터 파이프라인을 운영하는 데에 핵심적인 역할을 한다고 볼 수 있다.

- 데이터 처리량이 많을 경우 → 일시적으로 파티션 개수와 컨슈머 개수를 늘려서 병렬처리량을 늘리는 방법을 생각해볼 수 있다.
- 프로듀서가 보내는 데이터양은 동일한데 특정 파티션에서 컨슈머 랙이 늘어나고 있는 상황 → 해당 파티션에 할당된 컨슈머에 이슈가 발생했음을 유추할 수 있다.

그러나 컨슈머 애플리케이션을 운영하며 모니터링한다고 했을 때, 컨슈머 랙이 임계치에 도달할 때마다 알람을 받는 것은 무의미한 일이다.

*※ 프로듀서가 데이터를 많이 보내면 일시적으로 임계치가 넘어가는 현상이 발생할 수 있기 때문이다.*

카프카 버로우 - 컨슈머 랙 모니터링 도구

슬라이딩 윈도우 계산을 통해 문제가 생긴 파티션과 컨슈머의 상태를 표현 ⇒ 컨슈머 랙 평가

### 컨슈머 배포 프로세스

**중단 배포**

컨슈머 애플리케이션을 완전히 종료한 이후에 개선된 코드를 가진 애플리케이션을 배포하는 방식

기존 컨슈머 애플리케이션이 종료되면 더는 토픽의 데이터를 가져갈 수 없기에 컨슈머 랙이 늘어나며 지연이 발생한다.

→ 중단 배포를 사용할 경우 새로운 로직이 적용된 신규 애플리케이션의 실행 전후를 명확하게 특정 오프셋 지점으로 나눌 수 있다.

배포 시점의 오프셋을 로깅했을 때(카프카 버로우 등) 신규 로직 전후의 데이터를 명확하게 구분할 수 있고, 신규 애플리케이션에서 이슈가 발생했을 때 롤백이 가능

**무중단 배포**

- 블루/그린 배포: 이전 버전 애플리케이션과 신규 버전 애플리케이션을 동시에 띄워놓고 트래픽을 전환하는 방법

  파티션 개수와 컨슈머 개수가 동일하게 운영될 때 유용

  → 신규 버전 애플리케이션을 배포하고 동일 컨슈머 그룹으로 파티션을 구독하도록 설정하면 신규 버전 애플리케이션의 컨슈머들은 idle 상태로 대기

  이후 기존 애플리케이션을 모두 중단하게 되면 리밸런싱이 발생하면서 파티션은 모두 신규 컨슈머와 연동된다. (⇒ 짧은 리밸런스 시간으로 배포를 수행할 수 있다는 장점)

  동일하게 운영되지 않는다면 일부 파티션은 신규 애플리케이션에 할당되어 섞이게 되는 문제가 발생한다.

- 롤링 배포: 파티션 개수가 인스턴스 개수와 같거나, 그보다 많아야 한다.

  하나의 인스턴스를 신규 버전으로 실행하고 모니터링한 이후에 나머지 1개의 인스턴스를 신규 버전으로 배포하는 방법

  이 경우 2번의 리밸런스가 발생하고 파티션 개수가 많을수록 리밸런스 시간도 길어지게 되므로 파티션 개수가 많지 않은 경우에 효과적인 방법이다.

- 카나리 배포: 1개 파티션에 컨슈머를 따로 배정하여 일부 데이터에 대해 신규 버전의 애플리케이션이 우선적으로 처리하는 방식으로 테스트

## 스프링 카프카

---

### 스프링 카프카 프로듀서

스프링 카프카 프로듀서는 **카프카 템플릿**이라고 불리는 클래스를 사용하여 데이터를 전송할 수 있다.

**카프카 템플릿을 사용하는 방법**

1. 스프링 카프카에서 제공하는 기본 카프카 템플릿을 사용하는 방법
2. 직접 사용자가 카프카 템플릿을 프로듀서 팩토리로 생성하는 방법

   카프카 프로듀서에 대한 설정 이후 Bean으로 등록해서 사용하는 방법이다.


### 스프링 카프카 컨슈머

- Acknowledging Listener: 매뉴얼 커밋을 사용할 경우
- ConsumerAware Listener: KafkaConsumer 인스턴스에 직접 접근하여 컨트롤하고 싶은 경우

**타입에 따른 분류**

- 레코드 리스너 - 단 1개의 레코드를 처리한다.

  MessageListener: Record 인스턴스 단위로 프로세싱, 오토 커밋 또는 컨슈머 컨테이너의 AckMode를 사용하는 경우

  AcknowledgingMessageListener: Record 인스턴스 단위로 프로세싱, 매뉴얼 커밋을 사용하는 경우

  ConsumerAwareMessageListener: Record 인스턴스 단위로 프로세싱, 컨슈머 객체를 활용하고 싶은 경우

  AcknowledgingConsumerAwareMessageListener: Record 인스턴스 단위로 프로세싱, 매뉴얼 커밋을 사용하고 컨슈머 객체를 활용하고 싶은 경우

- 배치 리스너 - 배치 리스너는 기존 카프카 클라이언트 라이브러리의 poll메서드로 리턴받은 ConsumerRecords처럼 한 번에 여러 개 레코드들을 처리할 수 있다.

스프링 카프카에서는 커밋이라고 부르지 않고 AckMode라고 표현한다.

*※ AckMode 기본값: BATCH, enable.auto.commit=false*

**AckMode 종류**

[ContainerProperties.AckMode (Spring for Apache Kafka 3.3.2 API)](https://docs.spring.io/spring-kafka/api/org/springframework/kafka/listener/ContainerProperties.AckMode.html)